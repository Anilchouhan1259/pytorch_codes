{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b94a68d7-de4b-4b06-a695-0b7a2fd33f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ac70990-a8cc-4c85-8f32-2f4b27a93a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10eb4b4d0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "605b3dfe-57de-437f-b3cd-6ffbfec2fc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./datasets/fashion-mnist_train.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3605d04-bac0-4beb-b80f-9b60535c68e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7676efd4-bf6c-4c89-8595-02e400ac5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,1:].values\n",
    "y=df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0ef36e83-1b1d-4e15-94a6-d6b93cc0975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2fc3a8a2-4386-47bf-9a7e-4dc669a8c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/225.0\n",
    "x_test=x_test/225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f2d563d-39ae-4733-8d91-ac32c6839f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self,features,labels):\n",
    "        self.features=torch.tensor(features,dtype=torch.float32)\n",
    "        self.labels=torch.tensor(labels,dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    def __getitem__(self,ind):\n",
    "        return self.features[ind],self.labels[ind]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf2899df-d6d4-4adf-90a0-7e44fa6b7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset(x_train,y_train)\n",
    "test_dataset = customDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "04003a1d-2285-4649-9a45-d5ead1e1907b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0089, 0.0000, 0.0000, 0.0000, 0.3244, 0.0222,\n",
       "         0.0000, 0.0089, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6311, 0.7156, 0.9467,\n",
       "         0.6267, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000, 0.0000, 0.0000, 0.0044,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0756, 0.7422, 0.8622, 0.9200,\n",
       "         0.8400, 1.0089, 0.3289, 0.0000, 0.0222, 0.0000, 0.0044, 0.0089, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1467, 0.7022, 0.9556, 0.8533,\n",
       "         0.8889, 0.8267, 0.9778, 0.5778, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0089, 0.0133, 0.0178, 0.0178, 0.0133,\n",
       "         0.0089, 0.0000, 0.0000, 0.0000, 0.0000, 0.7200, 0.8711, 0.8844, 0.8711,\n",
       "         0.8800, 0.8933, 0.9200, 0.9200, 0.3822, 0.0178, 0.0000, 0.0000, 0.0311,\n",
       "         0.2311, 0.5333, 1.0667, 0.1822, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.3067, 0.9556, 0.8889, 0.8356, 0.7067,\n",
       "         0.7289, 0.8089, 0.8667, 0.9200, 0.9689, 0.9956, 1.1111, 0.9511, 0.8756,\n",
       "         0.9111, 0.9911, 0.9467, 0.9867, 0.2978, 0.0000, 0.0000, 0.0000, 0.0178,\n",
       "         0.0667, 0.1378, 0.3200, 0.3467, 0.7378, 1.0667, 0.8089, 0.6667, 0.5289,\n",
       "         0.5556, 0.5733, 0.6311, 0.7022, 0.7244, 0.8044, 0.9244, 0.9689, 0.9822,\n",
       "         0.9778, 0.9556, 0.9333, 0.8711, 0.9111, 0.6444, 0.0978, 0.7111, 0.9111,\n",
       "         0.9200, 0.9289, 0.9156, 0.9067, 0.8667, 0.8089, 0.6578, 0.4667, 0.5689,\n",
       "         0.5956, 0.6578, 0.6222, 0.5822, 0.6311, 0.6978, 0.7067, 0.6711, 0.7556,\n",
       "         0.8267, 0.8400, 0.8578, 0.8844, 0.8711, 0.9156, 0.8133, 0.0489, 0.2578,\n",
       "         0.3289, 0.4044, 0.5556, 0.7333, 0.8933, 0.9644, 0.9422, 0.8444, 0.6889,\n",
       "         0.6044, 0.6444, 0.6667, 0.6711, 0.6311, 0.5956, 0.6089, 0.6533, 0.6889,\n",
       "         0.7156, 0.7556, 0.7467, 0.7333, 0.8267, 0.8889, 0.9600, 0.8311, 0.0711,\n",
       "         0.0756, 0.0400, 0.0000, 0.0000, 0.0000, 0.0000, 0.3467, 0.7600, 1.0800,\n",
       "         0.9200, 0.8711, 0.8844, 0.9200, 0.9333, 0.9289, 0.9156, 1.1067, 1.0844,\n",
       "         1.0711, 1.0400, 1.0044, 0.9556, 0.9333, 0.9467, 1.0533, 1.1333, 0.7333,\n",
       "         0.0000, 0.0311, 0.1200, 0.1778, 0.1822, 0.0533, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0444, 0.2044, 0.2400, 0.2978, 0.2933, 0.2533, 0.2000, 0.1556,\n",
       "         0.1067, 0.0489, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0756, 0.2178, 0.4089, 0.4978, 0.3822,\n",
       "         0.2667, 0.1689, 0.0756, 0.0000, 0.0000, 0.0000, 0.0000, 0.0133, 0.0311,\n",
       "         0.0311, 0.0311, 0.0667, 0.0844, 0.0933, 0.0844, 0.0533, 0.0178, 0.0267,\n",
       "         0.0444, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0311, 0.0933,\n",
       "         0.1689, 0.2356, 0.2178, 0.2533, 0.2311, 0.2667, 0.2756, 0.2889, 0.2933,\n",
       "         0.3111, 0.3289, 0.3244, 0.3333, 0.3333, 0.3289, 0.3333, 0.2978, 0.2533,\n",
       "         0.2800, 0.2533, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]),\n",
       " tensor(7))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74874695-6719-4ce4-ae3a-cc1bef72684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True,pin_memory=True)\n",
    "test_dataloader= DataLoader(test_dataset,batch_size=32,shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c00132d9-ed3f-49b3-8a32-36f684d744cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self,num_of_features):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_of_features,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,10)         \n",
    "        )\n",
    "    def forward(self,features):\n",
    "        return self.model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "32354ddb-df57-4f14-959b-880ff09ff38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d5856ea4-37f4-4e76-8a00-9096d02fbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SimpleANN(x_train.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a1a580ce-8c36-45af-820a-605e7126ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "citeration = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d7a3c310-e969-4594-9e2d-bfa1bd464b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5e1e6b0e-df29-4e38-9f45-23946e4bb1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: 0.6245252492825191\n",
      "Epoch: 2 , Loss: 0.42743367994825043\n",
      "Epoch: 3 , Loss: 0.38411147879064084\n",
      "Epoch: 4 , Loss: 0.35705055251717566\n",
      "Epoch: 5 , Loss: 0.3344689627836148\n",
      "Epoch: 6 , Loss: 0.3218810750817259\n",
      "Epoch: 7 , Loss: 0.30614484356095395\n",
      "Epoch: 8 , Loss: 0.2952117714360356\n",
      "Epoch: 9 , Loss: 0.28427954148997864\n",
      "Epoch: 10 , Loss: 0.2734819379573067\n",
      "Epoch: 11 , Loss: 0.26775027192632356\n",
      "Epoch: 12 , Loss: 0.2581611140432457\n",
      "Epoch: 13 , Loss: 0.24949316652740042\n",
      "Epoch: 14 , Loss: 0.2428294148805241\n",
      "Epoch: 15 , Loss: 0.2378063898210724\n",
      "Epoch: 16 , Loss: 0.23197789440179864\n",
      "Epoch: 17 , Loss: 0.22369262045497695\n",
      "Epoch: 18 , Loss: 0.22065019097054997\n",
      "Epoch: 19 , Loss: 0.2151844173396627\n",
      "Epoch: 20 , Loss: 0.21033578078572948\n",
      "Epoch: 21 , Loss: 0.2052320196852088\n",
      "Epoch: 22 , Loss: 0.19943672912940383\n",
      "Epoch: 23 , Loss: 0.194382314397643\n",
      "Epoch: 24 , Loss: 0.19405937441190083\n",
      "Epoch: 25 , Loss: 0.1878156934340174\n",
      "Epoch: 26 , Loss: 0.18645072725228964\n",
      "Epoch: 27 , Loss: 0.18046945264873404\n",
      "Epoch: 28 , Loss: 0.1745578510047247\n",
      "Epoch: 29 , Loss: 0.1720919933306674\n",
      "Epoch: 30 , Loss: 0.17525884580177564\n",
      "Epoch: 31 , Loss: 0.16940931053770086\n",
      "Epoch: 32 , Loss: 0.16441903131765623\n",
      "Epoch: 33 , Loss: 0.1614821794629097\n",
      "Epoch: 34 , Loss: 0.16018640822110078\n",
      "Epoch: 35 , Loss: 0.155634051947544\n",
      "Epoch: 36 , Loss: 0.15520771456013124\n",
      "Epoch: 37 , Loss: 0.14930885695169369\n",
      "Epoch: 38 , Loss: 0.14586126135724287\n",
      "Epoch: 39 , Loss: 0.14183918293418052\n",
      "Epoch: 40 , Loss: 0.14448050626087933\n",
      "Epoch: 41 , Loss: 0.1403937820593516\n",
      "Epoch: 42 , Loss: 0.1366670935614966\n",
      "Epoch: 43 , Loss: 0.13720518297639986\n",
      "Epoch: 44 , Loss: 0.13509753457953533\n",
      "Epoch: 45 , Loss: 0.13313460082529732\n",
      "Epoch: 46 , Loss: 0.13056029311055317\n",
      "Epoch: 47 , Loss: 0.12949805110910287\n",
      "Epoch: 48 , Loss: 0.1248094613898235\n",
      "Epoch: 49 , Loss: 0.1197428036738808\n",
      "Epoch: 50 , Loss: 0.1208009966093426\n",
      "Epoch: 51 , Loss: 0.11810519134563705\n",
      "Epoch: 52 , Loss: 0.1146564014106989\n",
      "Epoch: 53 , Loss: 0.11628138983560105\n",
      "Epoch: 54 , Loss: 0.11180275377677754\n",
      "Epoch: 55 , Loss: 0.11157548471353948\n",
      "Epoch: 56 , Loss: 0.11261753833619878\n",
      "Epoch: 57 , Loss: 0.1093140225186944\n",
      "Epoch: 58 , Loss: 0.11058030184893869\n",
      "Epoch: 59 , Loss: 0.10320154700680481\n",
      "Epoch: 60 , Loss: 0.10161854125078147\n",
      "Epoch: 61 , Loss: 0.10036874084651935\n",
      "Epoch: 62 , Loss: 0.10147215720188493\n",
      "Epoch: 63 , Loss: 0.09964940198355665\n",
      "Epoch: 64 , Loss: 0.09909728215343784\n",
      "Epoch: 65 , Loss: 0.09837354524326898\n",
      "Epoch: 66 , Loss: 0.09785596848426698\n",
      "Epoch: 67 , Loss: 0.08930752157025078\n",
      "Epoch: 68 , Loss: 0.09508681932611701\n",
      "Epoch: 69 , Loss: 0.08967772505215059\n",
      "Epoch: 70 , Loss: 0.08680047831257495\n",
      "Epoch: 71 , Loss: 0.08781177606146472\n",
      "Epoch: 72 , Loss: 0.08415581317261482\n",
      "Epoch: 73 , Loss: 0.08895490162047402\n",
      "Epoch: 74 , Loss: 0.08819741087895817\n",
      "Epoch: 75 , Loss: 0.08510804229559532\n",
      "Epoch: 76 , Loss: 0.08374991369204751\n",
      "Epoch: 77 , Loss: 0.08368431126174983\n",
      "Epoch: 78 , Loss: 0.08138297872400532\n",
      "Epoch: 79 , Loss: 0.07687509505815493\n",
      "Epoch: 80 , Loss: 0.08337147542159073\n",
      "Epoch: 81 , Loss: 0.07558821321571789\n",
      "Epoch: 82 , Loss: 0.08250009019846523\n",
      "Epoch: 83 , Loss: 0.07581963268628654\n",
      "Epoch: 84 , Loss: 0.07115913956506605\n",
      "Epoch: 85 , Loss: 0.07088659952868087\n",
      "Epoch: 86 , Loss: 0.08006504749601784\n",
      "Epoch: 87 , Loss: 0.07607895258856782\n",
      "Epoch: 88 , Loss: 0.06515316430084932\n",
      "Epoch: 89 , Loss: 0.07510703988362608\n",
      "Epoch: 90 , Loss: 0.07057841200788001\n",
      "Epoch: 91 , Loss: 0.07014601640880573\n",
      "Epoch: 92 , Loss: 0.0726030877585581\n",
      "Epoch: 93 , Loss: 0.06455167263903422\n",
      "Epoch: 94 , Loss: 0.06555769588148298\n",
      "Epoch: 95 , Loss: 0.06876429480163886\n",
      "Epoch: 96 , Loss: 0.06816838637406666\n",
      "Epoch: 97 , Loss: 0.06187177368532866\n",
      "Epoch: 98 , Loss: 0.06366674465401835\n",
      "Epoch: 99 , Loss: 0.06167012981084796\n",
      "Epoch: 100 , Loss: 0.060010505914251555\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_epoch_loss = 0\n",
    "    for batch_features,batch_labels in train_dataloader:\n",
    "        batch_features,batch_labels = batch_features.to(device),batch_labels.to(device)\n",
    "        pred=model(batch_features)\n",
    "        loss = citeration(pred,batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_epoch_loss+=loss.item()\n",
    "    avg_loss = total_epoch_loss/len(train_dataloader)\n",
    "    print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a6df270-cc57-4a62-8d89-8c1ac98c2a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleANN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8804a1cd-ea19-4edb-9428-9804507b61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8829166666666667\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "with torch.no_grad():\n",
    "    for batch_features,batch_labels in test_dataloader : \n",
    "        batch_features,batch_labels= batch_features.to(device),batch_labels.to(device)\n",
    "        pred= model(batch_features)\n",
    "        _,predicted=torch.max(pred,1)\n",
    "        total+=batch_labels.shape[0]\n",
    "        correct+=(predicted==batch_labels).sum().item()\n",
    "    print(correct/total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a254a2f-7293-473b-9bc4-32e4393e8dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
