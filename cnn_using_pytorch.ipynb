{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abca74e2-30ef-4344-8691-37496f530872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b3ed0a-eed2-4c01-b7fd-7f1fd8d50865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d73b450>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8332ad-b8d7-4d0b-98d2-82e1348c7a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./datasets/fashion-mnist_train.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "619484d3-8e70-49f2-819c-493d75a65e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747ace84-1bad-4d67-89c4-f66d62bf7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,1:].values\n",
    "y=df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2822de39-6468-4198-997d-9b152426747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30e643c-5509-4a32-966f-6d3620f73db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/225.0\n",
    "x_test=x_test/225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5236c6d7-48e2-4b38-9e76-4d88d07be924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self,features,labels):\n",
    "        self.features=torch.tensor(features,dtype=torch.float32).reshape(-1,1,28,28)\n",
    "        self.labels=torch.tensor(labels,dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    def __getitem__(self,ind):\n",
    "        return self.features[ind],self.labels[ind]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e2c30c-984c-4de3-9de8-bb9a95793f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset(x_train,y_train)\n",
    "test_dataset = customDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa0e07e-35da-473b-baa0-53d6bb3d5dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0089, 0.0000, 0.0000,\n",
       "           0.0000, 0.3244, 0.0222, 0.0000, 0.0089, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6311,\n",
       "           0.7156, 0.9467, 0.6267, 0.0000, 0.0000, 0.0044, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0044, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0756, 0.7422, 0.8622,\n",
       "           0.9200, 0.8400, 1.0089, 0.3289, 0.0000, 0.0222, 0.0000, 0.0044,\n",
       "           0.0089, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1467, 0.7022, 0.9556, 0.8533,\n",
       "           0.8889, 0.8267, 0.9778, 0.5778, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0089, 0.0133, 0.0178, 0.0178, 0.0133, 0.0089, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.7200, 0.8711, 0.8844, 0.8711, 0.8800,\n",
       "           0.8933, 0.9200, 0.9200, 0.3822, 0.0178, 0.0000, 0.0000, 0.0311,\n",
       "           0.2311, 0.5333, 1.0667, 0.1822],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.3067, 0.9556, 0.8889, 0.8356, 0.7067, 0.7289, 0.8089,\n",
       "           0.8667, 0.9200, 0.9689, 0.9956, 1.1111, 0.9511, 0.8756, 0.9111,\n",
       "           0.9911, 0.9467, 0.9867, 0.2978],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0178, 0.0667, 0.1378, 0.3200, 0.3467,\n",
       "           0.7378, 1.0667, 0.8089, 0.6667, 0.5289, 0.5556, 0.5733, 0.6311,\n",
       "           0.7022, 0.7244, 0.8044, 0.9244, 0.9689, 0.9822, 0.9778, 0.9556,\n",
       "           0.9333, 0.8711, 0.9111, 0.6444],\n",
       "          [0.0978, 0.7111, 0.9111, 0.9200, 0.9289, 0.9156, 0.9067, 0.8667,\n",
       "           0.8089, 0.6578, 0.4667, 0.5689, 0.5956, 0.6578, 0.6222, 0.5822,\n",
       "           0.6311, 0.6978, 0.7067, 0.6711, 0.7556, 0.8267, 0.8400, 0.8578,\n",
       "           0.8844, 0.8711, 0.9156, 0.8133],\n",
       "          [0.0489, 0.2578, 0.3289, 0.4044, 0.5556, 0.7333, 0.8933, 0.9644,\n",
       "           0.9422, 0.8444, 0.6889, 0.6044, 0.6444, 0.6667, 0.6711, 0.6311,\n",
       "           0.5956, 0.6089, 0.6533, 0.6889, 0.7156, 0.7556, 0.7467, 0.7333,\n",
       "           0.8267, 0.8889, 0.9600, 0.8311],\n",
       "          [0.0711, 0.0756, 0.0400, 0.0000, 0.0000, 0.0000, 0.0000, 0.3467,\n",
       "           0.7600, 1.0800, 0.9200, 0.8711, 0.8844, 0.9200, 0.9333, 0.9289,\n",
       "           0.9156, 1.1067, 1.0844, 1.0711, 1.0400, 1.0044, 0.9556, 0.9333,\n",
       "           0.9467, 1.0533, 1.1333, 0.7333],\n",
       "          [0.0000, 0.0311, 0.1200, 0.1778, 0.1822, 0.0533, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0444, 0.2044, 0.2400, 0.2978, 0.2933, 0.2533,\n",
       "           0.2000, 0.1556, 0.1067, 0.0489, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0756, 0.2178, 0.4089, 0.4978, 0.3822,\n",
       "           0.2667, 0.1689, 0.0756, 0.0000, 0.0000, 0.0000, 0.0000, 0.0133,\n",
       "           0.0311, 0.0311, 0.0311, 0.0667, 0.0844, 0.0933, 0.0844, 0.0533,\n",
       "           0.0178, 0.0267, 0.0444, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0311, 0.0933, 0.1689,\n",
       "           0.2356, 0.2178, 0.2533, 0.2311, 0.2667, 0.2756, 0.2889, 0.2933,\n",
       "           0.3111, 0.3289, 0.3244, 0.3333, 0.3333, 0.3289, 0.3333, 0.2978,\n",
       "           0.2533, 0.2800, 0.2533, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor(7))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d07c89-6d5e-4064-ab88-4496efed5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True,pin_memory=True)\n",
    "test_dataloader= DataLoader(test_dataset,batch_size=32,shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a08ba03b-6886-4ce4-84c0-642f9b0584c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self,input_feature):\n",
    "        super().__init__()\n",
    "        self.features= nn.Sequential(\n",
    "            nn.Conv2d(input_feature,32,kernel_size=3,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            nn.Conv2d(32,64,kernel_size=3,padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            \n",
    "        )\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*7*7,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x= self.features(x)\n",
    "        x= self.classification(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff890baf-7eb2-498f-90b7-2287608231e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MyNN(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8aa2435-42b9-422c-8107-fe3585317ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5607a39f-5277-407e-bcd7-b546e4b9f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "citeration = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a21dde64-2fdd-43be-a0d8-2909e2a5f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=lr,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32c15d80-bf3b-4194-9ff4-3f83010a2f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: 2.4343582031726836\n",
      "Epoch: 2 , Loss: 2.1331076822280886\n",
      "Epoch: 3 , Loss: 2.028107855439186\n",
      "Epoch: 4 , Loss: 1.9599910276730856\n",
      "Epoch: 5 , Loss: 1.955018118262291\n",
      "Epoch: 6 , Loss: 1.9133216268221538\n",
      "Epoch: 7 , Loss: 1.9040337035655974\n",
      "Epoch: 8 , Loss: 1.897798668940862\n",
      "Epoch: 9 , Loss: 1.8906999042431514\n",
      "Epoch: 10 , Loss: 1.8950867652098338\n",
      "Epoch: 11 , Loss: 1.8785371878147126\n",
      "Epoch: 12 , Loss: 1.866512406349182\n",
      "Epoch: 13 , Loss: 1.8766234058141709\n",
      "Epoch: 14 , Loss: 1.8669428231318792\n",
      "Epoch: 15 , Loss: 1.8474117159843444\n",
      "Epoch: 16 , Loss: 1.854730988264084\n",
      "Epoch: 17 , Loss: 1.8563255363702773\n",
      "Epoch: 18 , Loss: 1.848164235830307\n",
      "Epoch: 19 , Loss: 1.8323100214004517\n",
      "Epoch: 20 , Loss: 1.823375139315923\n",
      "Epoch: 21 , Loss: 1.8356380840539932\n",
      "Epoch: 22 , Loss: 1.8231076658566794\n",
      "Epoch: 23 , Loss: 1.8179310425917308\n",
      "Epoch: 24 , Loss: 1.804753166079521\n",
      "Epoch: 25 , Loss: 1.8020689582626024\n",
      "Epoch: 26 , Loss: 1.7958900687297186\n",
      "Epoch: 27 , Loss: 1.7864856855074565\n",
      "Epoch: 28 , Loss: 1.7975189429918925\n",
      "Epoch: 29 , Loss: 1.7919523357152938\n",
      "Epoch: 30 , Loss: 1.7827580601771673\n",
      "Epoch: 31 , Loss: 1.792042224129041\n",
      "Epoch: 32 , Loss: 1.803902732372284\n",
      "Epoch: 33 , Loss: 1.7774697299400966\n",
      "Epoch: 34 , Loss: 1.7681380742788315\n",
      "Epoch: 35 , Loss: 1.7831046089331308\n",
      "Epoch: 36 , Loss: 1.7762724059025448\n",
      "Epoch: 37 , Loss: 1.7551329446633657\n",
      "Epoch: 38 , Loss: 1.7821888745625813\n",
      "Epoch: 39 , Loss: 1.7723920268217723\n",
      "Epoch: 40 , Loss: 1.775175185362498\n",
      "Epoch: 41 , Loss: 1.7739150633017222\n",
      "Epoch: 42 , Loss: 1.766549896121025\n",
      "Epoch: 43 , Loss: 1.7728054698705673\n",
      "Epoch: 44 , Loss: 1.7627613428433737\n",
      "Epoch: 45 , Loss: 1.7687726032733917\n",
      "Epoch: 46 , Loss: 1.7477140580415726\n",
      "Epoch: 47 , Loss: 1.7540465670426686\n",
      "Epoch: 48 , Loss: 1.753280419389407\n",
      "Epoch: 49 , Loss: 1.7689580178658169\n",
      "Epoch: 50 , Loss: 1.7402595092455546\n",
      "Epoch: 51 , Loss: 1.7656080956459046\n",
      "Epoch: 52 , Loss: 1.7610761779149373\n",
      "Epoch: 53 , Loss: 1.7513717344999313\n",
      "Epoch: 54 , Loss: 1.7568743429581324\n",
      "Epoch: 55 , Loss: 1.7509794237613678\n",
      "Epoch: 56 , Loss: 1.7540540078083675\n",
      "Epoch: 57 , Loss: 1.7559199636379879\n",
      "Epoch: 58 , Loss: 1.7535580917596818\n",
      "Epoch: 59 , Loss: 1.7447942668596903\n",
      "Epoch: 60 , Loss: 1.7507111436128617\n",
      "Epoch: 61 , Loss: 1.739926966071129\n",
      "Epoch: 62 , Loss: 1.7320746148427328\n",
      "Epoch: 63 , Loss: 1.749373736580213\n",
      "Epoch: 64 , Loss: 1.75797546907266\n",
      "Epoch: 65 , Loss: 1.7475782920916876\n",
      "Epoch: 66 , Loss: 1.7370843843619028\n",
      "Epoch: 67 , Loss: 1.742826962153117\n",
      "Epoch: 68 , Loss: 1.7480786480108896\n",
      "Epoch: 69 , Loss: 1.728127623597781\n",
      "Epoch: 70 , Loss: 1.7373140189647676\n",
      "Epoch: 71 , Loss: 1.7583806495666503\n",
      "Epoch: 72 , Loss: 1.7515808370908101\n",
      "Epoch: 73 , Loss: 1.7265567372639974\n",
      "Epoch: 74 , Loss: 1.7522030317783355\n",
      "Epoch: 75 , Loss: 1.7409510406255722\n",
      "Epoch: 76 , Loss: 1.7507685421705246\n",
      "Epoch: 77 , Loss: 1.7392652075688044\n",
      "Epoch: 78 , Loss: 1.7349797408183416\n",
      "Epoch: 79 , Loss: 1.7409445176124572\n",
      "Epoch: 80 , Loss: 1.7494219025373459\n",
      "Epoch: 81 , Loss: 1.7515688877105713\n",
      "Epoch: 82 , Loss: 1.7367739588419597\n",
      "Epoch: 83 , Loss: 1.7532674796978633\n",
      "Epoch: 84 , Loss: 1.7287878446181615\n",
      "Epoch: 85 , Loss: 1.7364659666021665\n",
      "Epoch: 86 , Loss: 1.7373630947271983\n",
      "Epoch: 87 , Loss: 1.739993067542712\n",
      "Epoch: 88 , Loss: 1.7296895385185878\n",
      "Epoch: 89 , Loss: 1.7441624350150426\n",
      "Epoch: 90 , Loss: 1.729784029940764\n",
      "Epoch: 91 , Loss: 1.7348892466624577\n",
      "Epoch: 92 , Loss: 1.7232294685443243\n",
      "Epoch: 93 , Loss: 1.7312270432313284\n",
      "Epoch: 94 , Loss: 1.7344686018427213\n",
      "Epoch: 95 , Loss: 1.7253387839396794\n",
      "Epoch: 96 , Loss: 1.754515751560529\n",
      "Epoch: 97 , Loss: 1.7265784265597661\n",
      "Epoch: 98 , Loss: 1.7390039289792378\n",
      "Epoch: 99 , Loss: 1.7219682723681131\n",
      "Epoch: 100 , Loss: 1.7252602868874867\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_epoch_loss = 0\n",
    "    for batch_features,batch_labels in train_dataloader:\n",
    "        batch_features,batch_labels = batch_features.to(device),batch_labels.to(device)\n",
    "        pred=model(batch_features)\n",
    "        loss = citeration(pred,batch_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_epoch_loss+=loss.item()\n",
    "    avg_loss = total_epoch_loss/len(train_dataloader)\n",
    "    print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fa0595b-b4eb-4540-b90a-17b9500610d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classification): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b60f6aa-cac6-4988-b619-751c0b9b49fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9245\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "with torch.no_grad():\n",
    "    for batch_features,batch_labels in test_dataloader : \n",
    "        batch_features,batch_labels= batch_features.to(device),batch_labels.to(device)\n",
    "        pred= model(batch_features)\n",
    "        _,predicted=torch.max(pred,1)\n",
    "        total+=batch_labels.shape[0]\n",
    "        correct+=(predicted==batch_labels).sum().item()\n",
    "    print(correct/total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9289ac2-d2ea-4b5f-9990-c3b25dff9d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
